{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import util.bq_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = \"recommendations\"\n",
    "PREDICTION_TABLE = \"predictions\"\n",
    "BUCKET = \"ka_recommendations/emails/\"\n",
    "BUCKET = \"ka_users/amy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Authenticating with BigQuery and GCS...\n"
     ]
    }
   ],
   "source": [
    "bq, gcs = util.bq_util.get_authed_clients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'amy/rec_training000000000000.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"rec_training_000000000000.csv\"\n",
    "filename = \"rec_training000000000000.csv\"\n",
    "util.bq_util.list_files_in_gcs_bucket(gcs, os.path.join(BUCKET, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.bq_util.download_files_from_gcs(gcs, os.path.join(BUCKET, filename))\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing + modeling functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bow_a_field(userdf, field):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    tokenizer = TfidfVectorizer()\n",
    "    title_text_feats = tokenizer.fit_transform(userdf[\"title\"].values).todense()\n",
    "    feature_names = tokenizer.get_feature_names()\n",
    "    d = {}\n",
    "    for i, feat in enumerate(feature_names):\n",
    "        d[feat] = [cell[0] for cell in title_text_feats[:,i].tolist()]\n",
    "    subdf = pd.DataFrame(data=d)\n",
    "    subdf = subdf.rename(columns={col: field + \"_\" + col for col in subdf.columns})\n",
    "    udf = userdf.copy()\n",
    "    for col in subdf.columns:\n",
    "        udf[col] = subdf[col].values\n",
    "    return udf\n",
    "\n",
    "def feature_processing(userdf):\n",
    "    \"\"\"Preprocess dataframe for a single user\"\"\"\n",
    "    DV = [\"engaged\"] # DV = did they engage with the content\n",
    "    features = [\"kind\", \n",
    "                \"title\", \n",
    "                \"domain\", \n",
    "                \"subject\", \n",
    "                \"topic\", \n",
    "                #\"keywords\"\n",
    "                \"tutorial\", \n",
    "                \"num_learners_per_day\", \n",
    "                \"total_score\",\n",
    "                \"content_id\",\n",
    "               ]\n",
    "    data = userdf[DV + features].dropna()\n",
    "    for field in [\"title\"]:\n",
    "        data = bow_a_field(data, field)\n",
    "    return data\n",
    "\n",
    "def split_data(data): \n",
    "    \"\"\"Split data into X, Y\"\"\"\n",
    "    Y = data[\"engaged\"]\n",
    "    content_ids = data[\"content_id\"].values\n",
    "    features = data[[col for col in data.columns if col not in (\"engaged\", \"content_id\")]]\n",
    "    # dummify anything still in categorical form\n",
    "    X = pd.get_dummies(features)\n",
    "    return X, Y, content_ids\n",
    "\n",
    "def train_and_evaluate(X_feats, Y_feats, clf, print_it=False):\n",
    "    \"\"\"Run cross-validation for crude model evaluation.\"\"\"\n",
    "    X = X_feats.values\n",
    "    Y = Y_feats.values\n",
    "    kf = sklearn.cross_validation.StratifiedKFold(Y, n_folds=2, shuffle=True, random_state=100)\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        if print_it:\n",
    "            print \"WORKING ON FOLD %s:\" %i\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        clf.fit(X_train, Y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "        probabilities = [p[1] for p in clf.predict_proba(X_test)]\n",
    "        print_metrics(Y_test, predicted, probabilities, print_it=print_it)\n",
    "    return Y_test, predicted, probabilities\n",
    "\n",
    "def print_metrics(true, predicted, proba, print_it=False):\n",
    "    \"\"\"For debugging/investigating individual user metrics.\"\"\"\n",
    "    auc = sklearn.metrics.roc_auc_score(true, proba)\n",
    "    accuracy = sklearn.metrics.accuracy_score(true, predicted)\n",
    "    f1 = sklearn.metrics.f1_score(true, predicted)\n",
    "    recall = sklearn.metrics.recall_score(true, predicted)\n",
    "    precision = sklearn.metrics.precision_score(true, predicted)\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(true, proba)\n",
    "    if print_it:\n",
    "        print \"accuracy: %s\" % accuracy\n",
    "        print \"auc: %s\" % auc\n",
    "        print \"f1: %s\" % f1\n",
    "        print \"recall: %s\" % recall\n",
    "        print \"precision: %s\" % precision\n",
    "        \n",
    "def final_predict(kaid, userdf, clf):\n",
    "    # split into positive and negative examples (all positive examples will go in training data)\n",
    "    positives = userdf[userdf[\"engaged\"]==1]\n",
    "    negatives = userdf[userdf[\"engaged\"]==0]\n",
    "    \n",
    "    # split remaining negatives into training and test (top half most popular will be test)\n",
    "    train = negatives[:len(negatives)/2]\n",
    "    test_ids = negatives[len(negatives)/2:].content_id.values\n",
    "    train_ids = pd.concat([train, positives]).content_id.values\n",
    "    prepped_data = feature_processing(userdf)\n",
    "    \n",
    "    #Split into X and Y + construct training and tests sets\n",
    "    X, Y, cids = split_data(prepped_data)\n",
    "    X_train, Y_train = [], []\n",
    "    X_test, Y_test, test_cids = [], [], []\n",
    "    for i, content_id in enumerate(cids):\n",
    "        if content_id in train_ids:\n",
    "            X_train.append(X.values[i])\n",
    "            Y_train.append(Y.values[i])\n",
    "        elif content_id in test_ids:\n",
    "            X_test.append(X.values[i])\n",
    "            Y_test.append(Y.values[i])\n",
    "            test_cids.append(content_id)\n",
    "            \n",
    "    # fit model and make predictions\n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    probas = [p[1] for p in clf.predict_proba(X_test)]\n",
    "    \n",
    "    # construct result structures for storing and using the data\n",
    "    df = pd.DataFrame(data={\n",
    "            \"prediction\": predictions,\n",
    "            \"probability\": probas,\n",
    "            \"content_id\": test_cids\n",
    "        })\n",
    "    \n",
    "    # awful hacky/arbitrary combination of personal + generic signals\n",
    "    r = pd.merge(df, userdf[[\"content_id\", \"node_slug\", \"total_score\", \"kind\", \"domain\", \"subject\"]], how=\"inner\")\n",
    "    r[\"pscore\"] = r[\"probability\"]**.5\n",
    "    r[\"general_zscore\"] = (r[\"total_score\"] - r[\"total_score\"].min())/(r[\"total_score\"].max() - r[\"total_score\"].min())\n",
    "    r[\"score\"] = (r[\"pscore\"] + r[\"general_zscore\"])/2\n",
    "    r = r.sort(\"score\", ascending=False)\n",
    "    r[\"kaid\"] = [kaid for i in range(len(r))]\n",
    "    return r\n",
    "\n",
    "def update_user_summary(userdf, kaid, true, prob, summary):\n",
    "    \"\"\"Update the table of single user summary stats.\"\"\"\n",
    "    summary[\"auc\"].append(sklearn.metrics.roc_auc_score(true, prob))\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(true, prob)\n",
    "    summary[\"num_positive\"].append(userdf.engaged.sum())\n",
    "    summary[\"kaid\"].append(kaid)\n",
    "    summary[\"joined\"].append(userdf.joined.max())\n",
    "    summary[\"fpr\"].append(fpr)\n",
    "    summary[\"tpr\"].append(tpr)\n",
    "    return summary\n",
    "\n",
    "def update_validation(kaid, true, pred, prob, validation):\n",
    "    \"\"\"Update the table of full truth vs. prediction stats\"\"\"\n",
    "    validation[\"true\"].extend(true)\n",
    "    validation[\"predicted\"].extend(pred)\n",
    "    validation[\"probability\"].extend(prob)\n",
    "    validation[\"kaid\"].extend([kaid for i in true])\n",
    "    return validation\n",
    "\n",
    "def classification_pipeline(df, top_n=100):\n",
    "    \"\"\"Run a the full classification pipeline to generate data for model evaluation, \n",
    "       and predictions for the recommender system.\"\"\"\n",
    "    \n",
    "    # initialize resulting table data\n",
    "    results = []\n",
    "    validation = {\"true\":[], \"predicted\":[], \"probability\": [], \"kaid\":[]}\n",
    "    summary = {\"auc\":[], \"num_positive\": [], \"kaid\": [], \"joined\": [], \"fpr\":[], \"tpr\":[]}\n",
    "    \n",
    "    # train, evaluate, and predict for each user individually\n",
    "    for kaid in df.kaid.unique():\n",
    "        userdf = df[df[\"kaid\"]==kaid]\n",
    "        if userdf[\"engaged\"].sum() <= 2:\n",
    "            print \"Skipping %s\" % kaid\n",
    "            continue\n",
    "        print \"Running %s\" % kaid\n",
    "        # preprocess data\n",
    "        prepped_data = feature_processing(userdf)\n",
    "        # train and evaluate model\n",
    "        X, Y, _ = split_data(prepped_data)\n",
    "        clf = sklearn.linear_model.LogisticRegression()\n",
    "        true, pred, prob = train_and_evaluate(X, Y, clf)\n",
    "        summary = update_user_summary(userdf, kaid, true, prob, summary)\n",
    "        validation = update_validation(kaid, true, pred, prob, validation)\n",
    "        # train full model + generate predictions\n",
    "        clf = sklearn.linear_model.LogisticRegression()\n",
    "        r = final_predict(kaid, userdf, clf)\n",
    "        results.append(r[:top_n])\n",
    "        \n",
    "    # construct final pandas dataframes\n",
    "    final_df = pd.concat(results)\n",
    "    validation_df = pd.DataFrame(data=validation)\n",
    "    summary_df = pd.DataFrame(data=summary)\n",
    "    return final_df, validation_df, summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train + Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:114: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping kaid_322962904607449063775472\n",
      "Running kaid_615122688051978532432289\n",
      "Running kaid_254884632901887636749179\n",
      "Skipping kaid_972312616504392465407997\n",
      "Running kaid_1021816025188633856726110\n",
      "Running kaid_177300951159445504653755\n",
      "Skipping kaid_19374345126826952044339\n",
      "Running kaid_407089334193359735364153\n",
      "Running kaid_1118218441556727937149064\n",
      "Skipping kaid_556022798793514927715493\n",
      "Skipping kaid_73776605891154008780640\n",
      "Running kaid_175634518858381301723625\n",
      "Running kaid_1055056106831724695622524\n",
      "Running kaid_447317448596630962092364\n",
      "Running kaid_226668233168615918510403\n",
      "Running kaid_126074402873291901558842\n",
      "Running kaid_694790541833528675386594\n",
      "Skipping kaid_1127696500567694409297156\n",
      "Running kaid_13656233299547006357001\n",
      "Skipping kaid_244119897602537658027200\n",
      "Running kaid_889915840622529423015409\n",
      "Running kaid_533239023227152353322535\n",
      "Running kaid_1026042980439454106016074\n",
      "Skipping kaid_325374501095247410801428\n",
      "Running kaid_456480905066980070292764\n",
      "Skipping kaid_192151328833642449115110\n",
      "Skipping kaid_84186644625651643679014\n",
      "Skipping kaid_1119520567302279872320347\n",
      "Skipping kaid_285230491758368655281723\n",
      "Running kaid_648373831964934217422125\n",
      "Skipping kaid_743766538369022350210895\n",
      "Running kaid_214303719021699868345243\n",
      "Running kaid_254055068707854738433899\n",
      "Running kaid_64106671508171806375507\n",
      "Skipping kaid_545540379645660246145069\n",
      "Running kaid_1062671325681245941021773\n",
      "Running kaid_246055050700925088152197\n",
      "Running kaid_501599264806630055935480\n",
      "Running kaid_1122329085994269647165893\n",
      "Skipping kaid_940224542961683573027986\n",
      "Running kaid_892263733480050244282033\n",
      "Running kaid_1125100843960839589593697\n",
      "Running kaid_501920967310323204258717\n",
      "Running kaid_58534003415733153218396\n",
      "Skipping kaid_1123648069412520665874207\n",
      "Running kaid_868898711767421875473793\n",
      "Running kaid_1052100867852720156546772\n",
      "Running kaid_823278597347115336926387\n",
      "Running kaid_119374797833378646010631\n",
      "Running kaid_654088764374228011666494\n",
      "Skipping kaid_772947842742359777683916\n",
      "Running kaid_489335300841173909571974\n",
      "Skipping kaid_606579190726124429723926\n",
      "Running kaid_811067182012437984969994\n",
      "Running kaid_47871280375790675048719\n",
      "Running kaid_1153757574839377431023960\n",
      "Running kaid_495873561237902626053420\n",
      "Running kaid_227459258060562838014659\n",
      "Skipping kaid_988944226525128615460921\n",
      "Running kaid_388875884404163674437185\n",
      "Running kaid_42212212109433004400296\n",
      "Running kaid_948469821003117765366936\n",
      "Running kaid_984832938996648580335358\n",
      "Skipping kaid_290657002422660855950247\n",
      "Skipping kaid_1153336294682633813125123\n",
      "Skipping kaid_998355490805291061907581\n",
      "Running kaid_1180652873038472009250875\n",
      "Running kaid_300206406872614661774357\n",
      "Running kaid_664074153260363528223780\n",
      "Skipping kaid_345400575700767057989355\n",
      "Skipping kaid_445865885051156546517178\n",
      "Running kaid_723060387184230234615652\n",
      "Running kaid_383406659075524741468894\n",
      "Running kaid_708334925242068561270111\n",
      "Skipping kaid_911339152645296679773163\n",
      "Running kaid_150790587970262881988680\n",
      "Running kaid_1116753190679129916060198\n",
      "Skipping kaid_1106386709890039248044024\n",
      "Running kaid_121658591999225979575457\n",
      "Running kaid_627620453393336374322232\n",
      "Running kaid_906983633787217430498350\n",
      "Running kaid_1191210916651667609836716\n",
      "Running kaid_671890100872033226989013\n",
      "Running kaid_178131793263413285236621\n",
      "Running kaid_117830456844565652389833\n",
      "Running kaid_1201546805945210805881428\n",
      "Skipping kaid_667583961928025118712059\n",
      "Skipping kaid_907719073708591576222492\n",
      "Skipping kaid_130005627098908667476885\n",
      "Skipping kaid_11526414680411168424449\n",
      "Skipping kaid_11081676693564563537834\n",
      "Skipping kaid_224532872513214809867097\n",
      "Running kaid_1047156263735473840717453\n",
      "Running kaid_473203674798532863454026\n",
      "Skipping kaid_789794698556175322518798\n",
      "Running kaid_668703183939960114219835\n",
      "Skipping kaid_180706567931426476315946\n",
      "Running kaid_86473285108773088443974\n",
      "Skipping kaid_646404689686985898578969\n",
      "Skipping kaid_1029804019778862851378411\n"
     ]
    }
   ],
   "source": [
    "final_df, validation_df, summary_df = classification_pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>node_slug</th>\n",
       "      <th>total_score</th>\n",
       "      <th>kind</th>\n",
       "      <th>domain</th>\n",
       "      <th>subject</th>\n",
       "      <th>pscore</th>\n",
       "      <th>general_zscore</th>\n",
       "      <th>score</th>\n",
       "      <th>kaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>x7aa228af</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701305</td>\n",
       "      <td>v/programming-intro</td>\n",
       "      <td>48.840667</td>\n",
       "      <td>Video</td>\n",
       "      <td>computing</td>\n",
       "      <td>computer-programming</td>\n",
       "      <td>0.837439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918720</td>\n",
       "      <td>kaid_615122688051978532432289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2600769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132428</td>\n",
       "      <td>v/adding-fractions-with-unlike-denominators</td>\n",
       "      <td>31.792000</td>\n",
       "      <td>Video</td>\n",
       "      <td>math</td>\n",
       "      <td>fr-seventh-grade-math</td>\n",
       "      <td>0.363907</td>\n",
       "      <td>0.636541</td>\n",
       "      <td>0.500224</td>\n",
       "      <td>kaid_615122688051978532432289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2600759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083351</td>\n",
       "      <td>v/multiplying-fractions</td>\n",
       "      <td>27.366000</td>\n",
       "      <td>Video</td>\n",
       "      <td>math</td>\n",
       "      <td>arithmetic</td>\n",
       "      <td>0.288707</td>\n",
       "      <td>0.542183</td>\n",
       "      <td>0.415445</td>\n",
       "      <td>kaid_615122688051978532432289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>183171788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045065</td>\n",
       "      <td>v/elements-and-atoms</td>\n",
       "      <td>23.590667</td>\n",
       "      <td>Video</td>\n",
       "      <td>science</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>0.212285</td>\n",
       "      <td>0.461697</td>\n",
       "      <td>0.336991</td>\n",
       "      <td>kaid_615122688051978532432289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>19647488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060904</td>\n",
       "      <td>v/negative-numbers-introduction</td>\n",
       "      <td>21.036000</td>\n",
       "      <td>Video</td>\n",
       "      <td>math</td>\n",
       "      <td>pre-algebra</td>\n",
       "      <td>0.246786</td>\n",
       "      <td>0.407234</td>\n",
       "      <td>0.327010</td>\n",
       "      <td>kaid_615122688051978532432289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    content_id  prediction  probability  \\\n",
       "683  x7aa228af           1     0.701305   \n",
       "768    2600769           0     0.132428   \n",
       "397    2600759           0     0.083351   \n",
       "578  183171788           0     0.045065   \n",
       "67    19647488           0     0.060904   \n",
       "\n",
       "                                       node_slug  total_score   kind  \\\n",
       "683                          v/programming-intro    48.840667  Video   \n",
       "768  v/adding-fractions-with-unlike-denominators    31.792000  Video   \n",
       "397                      v/multiplying-fractions    27.366000  Video   \n",
       "578                         v/elements-and-atoms    23.590667  Video   \n",
       "67               v/negative-numbers-introduction    21.036000  Video   \n",
       "\n",
       "        domain                subject    pscore  general_zscore     score  \\\n",
       "683  computing   computer-programming  0.837439        1.000000  0.918720   \n",
       "768       math  fr-seventh-grade-math  0.363907        0.636541  0.500224   \n",
       "397       math             arithmetic  0.288707        0.542183  0.415445   \n",
       "578    science              chemistry  0.212285        0.461697  0.336991   \n",
       "67        math            pre-algebra  0.246786        0.407234  0.327010   \n",
       "\n",
       "                              kaid  \n",
       "683  kaid_615122688051978532432289  \n",
       "768  kaid_615122688051978532432289  \n",
       "397  kaid_615122688051978532432289  \n",
       "578  kaid_615122688051978532432289  \n",
       "67   kaid_615122688051978532432289  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.barplot(x=\"true\", y=\"probability\", data=validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(validation_df[\"true\"], validation_df[\"probability\"])\n",
    "print sklearn.metrics.roc_auc_score(validation_df[\"true\"], validation_df[\"probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=[4,4])\n",
    "plt.scatter(fpr, tpr)\n",
    "plt.ylim([-.02,1.02])\n",
    "plt.xlim([-.02,1.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = summary_df.auc.mean()\n",
    "se = summary_df.auc.std(dof=0)/np.sqrt(len(summary_df))\n",
    "#plt.bar([0], [m], yerr=[se])\n",
    "print m, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_df.auc.hist(bins=25, figsize=[6,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(\"auc\", \"num_positive\", summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=[4,4])\n",
    "for i, row in summary_df[:10].iterrows():\n",
    "    f, ax = plt.subplots(figsize=[4,4])\n",
    "    plt.scatter(row[\"fpr\"], row[\"tpr\"])\n",
    "    plt.title(row[\"kaid\"])\n",
    "    plt.ylim([-.02,1.02])\n",
    "    plt.xlim([-.02,1.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions back to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for kaid in final_df.kaid.unique():\n",
    "    print kaid\n",
    "    print final_df[final_df[\"kaid\"]==kaid][:10][\"node_slug\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = [\"kaid\", \"kind\", \"content_id\", \"node_slug\", \"domain\", \"subject\", \"probability\", \"prediction\", \"score\"]\n",
    "predictions_to_save = final_df[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Insert is 15% Complete\n",
      "Streaming Insert is 31% Complete\n",
      "Streaming Insert is 46% Complete\n",
      "Streaming Insert is 62% Complete\n",
      "Streaming Insert is 78% Complete\n",
      "Streaming Insert is 93% Complete\n",
      "Streaming Insert is 100% Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import util.secrets\n",
    "util.bq_util.upload_df_to_bq(bq, predictions_to_save, util.secrets.BIGQUERY_PROJECT_ID, DATASET, PREDICTION_TABLE, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
